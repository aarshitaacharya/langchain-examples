{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f995287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2149e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: packaging in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee1618d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "data = pd.read_csv(StringIO(res.text), sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22602c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data['sentence_A'].tolist()\n",
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)\n",
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be8bbf",
   "metadata": {},
   "source": [
    "since this is not a very large number, we need more sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e4a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb445d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723, 3)\n",
      "(701, 3)\n",
      "(750, 3)\n",
      "(561, 3)\n",
      "(750, 3)\n",
      "(750, 3)\n",
      "(1500, 3)\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, on_bad_lines='skip')\n",
    "    print(data.shape)\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcf12ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97671984",
   "metadata": {},
   "source": [
    "remove duplicates now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "022fe3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [word for word in list(set(sentences)) if type(word) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961faffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (5.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: tqdm in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (4.48.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (10.4.0)\n",
      "Requirement already satisfied: scipy in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sentence_transformers) (1.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: filelock in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: sympy in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aarshitaacharya/.pyenv/versions/3.10.16/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b6bfb",
   "metadata": {},
   "source": [
    "let us use indexflatl2, i.e the euclidian distance between all points and our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908951c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766dfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cf1b9",
   "metadata": {},
   "source": [
    "some indexes need to be trained before loading, so we can check using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a0454b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2dce3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275144e",
   "metadata": {},
   "source": [
    "let number of nearest neighbors be k, and search query be xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0892328",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c276c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10947 10138  8981  9991]]\n",
      "CPU times: user 7.24 ms, sys: 2.1 ms, total: 9.34 ms\n",
      "Wall time: 7.17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c06e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5866\tTwo boys in a field kicking a soccer ball.\n",
      "3917\tBrown dog running on grass.\n",
      "6183\tA black and white dog is swimming in a large green lake.\n",
      "9407\tTwo women shearing a white sheep in a wooden stall.\n"
     ]
    }
   ],
   "source": [
    "for i in [5866, 3917, 6183, 9407]:\n",
    "    print(f\"{i}\\t{sentences[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc65a6",
   "metadata": {},
   "source": [
    "these are clearly great matches, now let us extract the actual numerical vectors from faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecd51ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vecs = np.zeros((k,d))\n",
    "\n",
    "for i, val in enumerate(I[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8003743f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705cd2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01627047,  0.22325911, -0.15037431, -0.30747238, -0.27122411,\n",
       "       -0.10593214, -0.06460946,  0.04738141, -0.73349041, -0.37657666,\n",
       "       -0.76762801,  0.16902865,  0.53107691,  0.51176602,  1.14415848,\n",
       "       -0.0856294 , -0.67240065, -0.96637076,  0.0254542 , -0.21559823,\n",
       "       -1.25656521, -0.82982141, -0.09824999, -0.21850841,  0.50610226,\n",
       "        0.10527912,  0.50396878,  0.6524294 , -1.39458692,  0.6584751 ,\n",
       "       -0.21525329, -0.22487469,  0.81818318,  0.08464345, -0.76141715,\n",
       "       -0.28928268, -0.09825802, -0.73046142,  0.07855809, -0.84354591,\n",
       "       -0.59242058,  0.77471322, -1.20920563, -0.22757955, -1.30733585,\n",
       "       -0.23081516, -1.31322575,  0.0162904 , -0.97285455,  0.19308192,\n",
       "        0.4742457 ,  1.18920982, -1.96741343, -0.70061046, -0.29638696,\n",
       "        0.60533744,  0.62407446, -0.70340371, -0.8675428 ,  0.17673112,\n",
       "       -0.19170494, -0.02951982,  0.22623539, -0.16695476, -0.80402517,\n",
       "       -0.45918974,  0.69675493, -0.24928208, -1.01478684, -0.921745  ,\n",
       "       -0.33842704, -0.39296842, -0.83734846, -0.11479267,  0.46049762,\n",
       "       -1.45211172,  0.60310435,  0.3869625 , -0.04061214,  0.00453169,\n",
       "        0.24117811,  0.0539625 ,  0.07506377,  1.05115831,  0.12383986,\n",
       "       -0.71281171,  0.11722878,  0.52238137, -0.04581127,  0.26827106,\n",
       "        0.85985392, -0.35669914, -0.64667016, -0.54357988, -0.04310489,\n",
       "        0.95139176, -0.15605712, -0.49625301, -0.11140267,  0.15610091])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3566e86",
   "metadata": {},
   "source": [
    "indexflatl2 is computationally expensive when used alone, and does not scale well. this is because it is an exhaustive search and our query vector is compared to every other vector in our index.\n",
    "\n",
    "better approach is to partition the index using voronoi cells"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
